# rust-svelte-setup

This project is an exploration in creating a standard setup for a microservice backend using Rust. The main focus is on backend architecture, simple CRUD operations, no event-driven architecture. The focus is on simplicity, type safety and testability.

# Architecture

## Overview

This project is an opinionated base setup for sveltekit apps with a rust based microservice backend.

## App

There is nothing particularly interesting in the app setup. I just like using Svelte and the setup is straightforward.
The app uses prerendering rather than server-side rendering, since the backend serves json responses directly. This means the HTML for each page is generated ahead of time during the build process, and any dynamic data is fetched from the backend after the page loads. This might not be suitable for more complex apps.

## Services

The backend consists of rust microservices. A clients request always reaches the `gateway` service where it is authenticated and forwarded to the respective microservice.
The gateway exposes a restful http server (`axum`). Within the backend, the communication is done through `grpc` (`tonic`). Each microservices has its own protobuf file defining the service and models.

#### Microservice structure

Each microservice is focused on simple CRUD operations and uses a straightforward structure. The architecture decouples the database/repository layer from the service logic. If complexity grows, you can further split responsibilities (e.g., add a dedicated service layer for domain logic).

A typical microservice (see [`dummy`](./services/dummy)) will have the following files:
- `main.rs`: setup (read env variables, open db connection) and run the service
- `lib.rs`: exposes service boundaries (such as `proto.rs`) for other microservices (see Microservice boundaries)
- `server.rs`: implements the gRPC endpoints and service logic
    - Each endpoint typically gets its own file (e.g., `get_entity.rs`)
- `db.rs`: database/repository layer for CRUD operations
- `proto.rs`: generated code from the protobuf definitions (does not need to be checked in git)
- `utils.rs`: shared methods between endpoints, models, etc.
- `error.rs`: error types for endpoints and database operations
- `client.rs`: gRPC client implementation + service mocks (auto generated code)

See also [Master hexagonal architecture in Rust](https://www.howtocodeit.com/articles/master-hexagonal-architecture-rust).

#### Microservice boundaries (`lib.rs`)

Microservices must have access to the api layer of other microservices, which means they must have access to the proto generated client and request/response messages of other microservices. This may be solve by - compiling the protos in a common `proto` library and including the common library in the microservice, or - compiling the proto that belongs to the service as part of the service and exposing it in `lib.rs`.
This setup uses the second solution. It avoids introducing a shared `proto` library and additionally each service can define which part of the proto it wants to expose. Note: the `lib.rs` should not expose more than needed by other service, so usually it only exposes the full or parts of the `proto.rs`.

#### Shared dependencies (`workspace`)

Microservices have a lot of dependencies in common, such as tonic, prost, tokio, serde etc. This may lead to a drift in dependency versions, where microservice a depends on a different version of package x than microservice b. The solution is to put all microservices in a `workspace` and define the share dependencies as a workspace dependency.

#### Deployment of microservices

#### Deploy a single microservice (`docker`)

The `Dockerfile` for each microservice is autogenerated using the [`scripts/docker-gen`](./scripts/docker-gen) script. This approach ensures that the Dockerfile only includes the microservice itself and the code from any services or packages it depends on. This is critical for optimal caching, especially when using `cargo-chef` to separate dependency compilation from service code builds.

All microservices of the backend are deployed together with docker compose.

#### Cache external dependencies between docker builds (`cargo-chef`)

This setup uses `cargo-chef` to split the build into two steps:
1. Compile all external dependencies (which change rarely)
2. Compile the microservice's actual binary

This separation allows Docker to cache the dependency layer, so rebuilding is much faster when only your service code changes.

I use a custom version of `cargo-chef` (not the main release), because of a fix I contributed ([PR #324](https://github.com/LukeMathWalker/cargo-chef/pull/324)) that minimizes the recipe for workspaces. With this fix, a workspace member (microservice or package) will only rebuild if one of its dependencies changes, instead of rebuilding too often as before.

#### Alternative docker strategy

At the moment I build the binary within the docker build process. For Rust images this can be very slow üêå. I put a lot of effor into caching everything optimally and reduce this time, but if a central dependency changes this can be a pain.An alternative would be to build the binary outside of docker and copy the binary into a minimal docker image (e.g., `scratch` or `alpine`). If I am honest, this sounds like the more scalable approach. But my software engineering pride resisted that idea in the beginning, there is something more elegant about building everything within docker.

## CI/CD

This project currently does **not** have a CI/CD pipeline set up but you definitely should add one. I've just not gotten around to do it yet.

## Authentication

Authentication is hand-rolled using information from [lucia](https://lucia-auth.com/). For details, see [`services/auth`](./services/auth). **This is not production-grade security. I'm not a security expert. Do really not use this for your super private production app! Each security flaw is fully on me, and honestly you shouldn't trust my authentication anyway. But I believe that you already know this.**

## Protos

Communication in the backend is done via `gRPC`. `proto` files are compiled into rust and typescript code, thus the backend can share request/response models with the frontend.

## Routing

I use **Traefik** as a reverse proxy to route requests to the backend or the frontend. Setting it up was straightforward, at least I dont remember any major issues.

## Testing

#### Unit tests

For unit tests I use [`rstest`](https://github.com/la10736/rstest) for table-driven testing. This makes it easy to cover multiple scenarios.

#### Database unit tests

Database unit tests use [`testcontainers`](https://docs.rs/testcontainers/latest/testcontainers/) to spin up a real postgres database.

#### Integration tests

Integration tests also use `testcontainers` to spin up all required services. These tests are located in [`services/gateway/tests`](./services/gateway/tests) and check the interactions between microservices in a realistic environment.

## Tracing

I use **OpenTelemetry** to instrument and collect traces. The traces are sent to **Jaeger** by default, but this can
be swapped with other **OpenTelemetry** compatible backends.

#### Inter-service tracing

Traces are propagated between microservices
- Sending: Interceptors inject/extract context and add a `trace_id`.
- Receiving: Middleware picks up the context and records the `trace_id`.

### Further Reading

- [Logging basics](https://heikoseeberger.de/2023-07-29-dist-tracing-1/)
- [Tracing in a single service](https://heikoseeberger.de/2023-08-18-dist-tracing-2/)
- [Inter-service tracing](https://heikoseeberger.de/2023-08-28-dist-tracing-3/)

# How to run

1. Copy `.env.example` to `.env` and adjust as needed.
2. Generate code and Dockerfiles:
   ```
   just generate
   ```
3. Build and deploy the backend:
   ```
   just build-services
   just deploy
   ```
4. To run the app locally (in the `app` directory):
   ```
   npm run dev -- --open
   ```
   Or build and deploy the app:
   ```
   just build-app
   just deploy-app
   ```

Do I promise this works flawlessly? No. There might be the one or other steps you have to do manually. Feel free to let me know.

# But now be real, how does it compare to go?

I use go professionally, so I think I can give a bit of perspective. The tldr is: for large software projects I‚Äôd still choose go for the majority of services, but I‚Äôd definitely consider Rust for performance-critical parts (see this good read: https://engineering.grab.com/counter-service-how-we-rewrote-it-in-rust). So having a standard Rust setup in the toolkit is a win. For a hobby project like this one? I just prefer writing Rust. Its like solzing puzzles for me.

**What I love about Rust:**
- I just love the language more than Go. It‚Äôs more expressive and I feel good if I manage to write a nice functional style map or find a good use case for traits.
- Type safety. In Go it‚Äôs easy to forget passing values to structs and let‚Äôs be honest, who creates explicit constructors for everything?
- Performance: blazingly fast. But have I benchmarked? No. And oes it matter for my app with 1 user (me)? Also no. 
- Nil pointer exception: In Go it‚Äôs just a tad too easy to get a nil pointer exception and crash your microservice. Want to access a nested proto struct but haven‚Äôt checked the parent for nil? Boom...
- Compile with features: It‚Äôs nice to use features to gate testutils behind a service. In Go, it‚Äôs not straightforward to share testutils without polluting the public API between services.
- Error handling: I don‚Äôt mind Go‚Äôs verbosity, but Rust has more batteries here with `anyhow` and `thiserror`. It just clicks more for me even though I haven‚Äôt fully found my groove.
- No garbage collection: Just one problem less to care for.

**The negatives:**
- The big one is compile time/docker time. Rebuilding a full service from scratch in Docker on a mac can take up to 10 minutes. Want to parallelize this over 10 microservices? Your memory is killed. I put a lot of effort into optimizing caching, using cargo-chef, fixing cargo-chef, autogenerating optimal Dockerfiles (see architecture). But here Go just wins, by a margin that‚Äôs not even fun. How does it compile so fast? Maybe I just need to crank some compiler flags in Rust, but I haven‚Äôt gotten around to that.
- Table testing is a bit cumbersome in Rust. I use rstest and really like it, but it‚Äôs macro-based, which always breaks my formatting in nvim...
- gRPC gateway: I thought this was a standard gRPC thing. Was surprised Rust doesn‚Äôt have a good gRPC gateway. Maybe tonic adds one at some point? (https://github.com/hyperium/tonic/issues/332)
- HTTP/gRPC middleware: Took me quite some time to write gRPC middleware in Rust. That‚Äôs a lot easier in Go, but once you figure out the Rust/tower way, it‚Äôs kinda fun.
- I like how easy it is to onboard new people in Go while in Rust I‚Äôd probably spend days explaining generics, lifetimes, async traits and would fumble most of the explanations. What's that Pin thing again?

# Where is it used so far?

A backend with a similar setup to this one powers my personal website for tracking running data: [runaround.world](https://runaround.world) (feel free to give it a try, but its early stage - it only supports data from polar and strava at the moment). It works really well. Rust + Postgres delivers the performance you'd expect and in practice there's no need to optimize beyond just writing sane Rust code. So don't worry about a few clones here and there. I like the type safety that Rust provides, there are rarely any issues that I have to debug after it compiles. And if there are issues, tracing helps to track them down quickly.

# AI usage

When I wrote the majority of this project, I didn‚Äôt have any agentic AI magic at my disposal. So pretty much all of this code is written by me. I do remember some long ChatGPT sessions when tracing between services wouldn‚Äôt work or a middleware broke, but those led me down Dantes hell before I decided to just sit down with myself and fix it.

That said I did use AI for factoring out my endpoints into separate files. [In the beninging](https://www.youtube.com/watch?v=vacJSHN4ZmY) I had every endpoint in one file, but as the code and tests grew, it became too much. AI helped me split things up in separate files.
And I thing the [docker-gen](./scripts/docker-gen) script is also mostly ai generated, although now I regret it because I like writing scripts that autogenerate code.

I swear I did not let AI write my authentication. Each security flaw is fully on me, and to be honest, you shouldn't trust my authentication anyway.

# Similar Projects

There are a few similar projects from which I drew inspiration, however there weren't as many as I expected. Here are some of them:

- [rusve](https://github.com/mpiorowski/rusve)
- [rust-microservice-template](https://github.com/nkz-soft/rust-microservice-template)
- [rust-simple-event-driven-microservices](https://github.com/Jamesmallon1/rust-simple-event-driven-microservices)
